{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputmask = torch.tensor([[1]*3], dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [1],\n",
       "         [1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputmask.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = torch.tensor([[[1,2,3],[1,2,3],[1,2,3]], [[1,2,3],[1,2,3],[1,2,3]]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[1,1,0], [1,0,0]], dtype=torch.int)\n",
    "tm = torch.tril(torch.ones(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [1],\n",
       "         [0]],\n",
       "\n",
       "        [[1],\n",
       "         [0],\n",
       "         [0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = torch.stack([[torch.tensor([1,1,0], dtype=torch.int),torch.tensor([1,0,0], dtype=torch.int),torch.tensor([1,1,1],dtype=torch.int)][i] for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [1],\n",
       "         [0]],\n",
       "\n",
       "        [[1],\n",
       "         [0],\n",
       "         [0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wei = th.masked_fill(tm==0, float(\"-inf\"))\n",
    "wei = th.masked_fill(min.unsqueeze(2) == 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [1., 2., 3.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n",
      "d\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "on = True\n",
    "while on:\n",
    "    q=input()\n",
    "\n",
    "    print(q)\n",
    "    if q == \"quit\":\n",
    "        on = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cl(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tab = torch.nn.Embedding(3, 32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tab(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.tensor([[32],[32],[32]],dtype=torch.int)\n",
    "model = cl()\n",
    "a, T = emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5741,  0.3800, -1.3000,  0.4301,  1.1825, -1.8453,  0.6297,  0.8339,\n",
       "          1.2079, -1.1570, -0.0930,  0.0070,  0.8128,  0.8856,  0.4237, -1.3723,\n",
       "          0.5453, -0.6681, -1.3226,  1.7194,  0.0357,  0.4929, -0.8637, -0.9682,\n",
       "          2.7969, -1.1800,  0.6577, -2.5229,  0.4473,  0.3468, -0.6053, -0.2795]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.arange(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.normalizers import Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "src_tokenizer.pre_tokenizer = Whitespace()\n",
    "src_tokenizer.normalizer = Lowercase()\n",
    "trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[SOS]\", \"[EOS]\", \"[PAD]\"], min_frequency=2)\n",
    "src_tokenizer.train([\"D:/robo_data/train.source\"], trainer=trainer)\n",
    "src_vocab_size = src_tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 43, 3307, 2745, 4342]\n",
      "[1, 43, 3307, 2745, 4342]\n"
     ]
    }
   ],
   "source": [
    "s = src_tokenizer.encode(\"[SOS] \" + \"was ist das dog\").ids\n",
    "print(s)\n",
    "s2 = src_tokenizer.encode(\"[SOS] \" + \"WAs\\nIst DAS dog\").ids\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'was ist das dog'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokenizer.decode(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> was ist, das dog.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<PAD> \".lower() + \"WAs Ist, DAS dog.\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "th2 = th.view(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "th2 = torch.tensor([[1.2,2.2,3.5,4.3,5.1,10.5]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(th2, num_samples=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
